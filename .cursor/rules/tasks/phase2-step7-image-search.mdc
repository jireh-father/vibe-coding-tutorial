---
description:
globs:
alwaysApply: false
---
# 7ë‹¨ê³„: ì´ë¯¸ì§€ ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„

## ğŸ¯ ëª©í‘œ
ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• - Google Vision API ì—°ë™, ì´ë¯¸ì§€ ë¶„ì„, ìƒí’ˆ ì‹ë³„, ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰

## ğŸ“‹ ìƒì„¸ íƒœìŠ¤í¬

### 7.1 Google Vision API ì—°ë™

#### í™˜ê²½ ì„¤ì • ì—…ë°ì´íŠ¸
```env
# Google Vision API
GOOGLE_VISION_API_KEY=your_vision_api_key_here
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account-key.json

# Image Processing
MAX_IMAGE_SIZE=10485760  # 10MB
SUPPORTED_IMAGE_FORMATS=jpg,jpeg,png,webp
IMAGE_ANALYSIS_TIMEOUT=30

# Vision API Settings
VISION_MAX_RESULTS=10
VISION_CONFIDENCE_THRESHOLD=0.7
```

#### requirements.txt ì—…ë°ì´íŠ¸
```txt
# ê¸°ì¡´ ì˜ì¡´ì„±...

# Google Vision API
google-cloud-vision==3.4.5
google-auth==2.23.4

# Image Processing
Pillow==10.1.0
opencv-python==4.8.1.78
numpy==1.24.3

# OCR and Text Processing
pytesseract==0.3.10
easyocr==1.7.0

# Additional utilities
requests==2.31.0
aiofiles==23.2.1
```

### 7.2 ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤

#### ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ (`src/agent/services/image_analysis.py`)
```python
import os
import io
import base64
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from PIL import Image
import cv2
import numpy as np
from google.cloud import vision
import logging

logger = logging.getLogger(__name__)

class ImageAnalysisService:
    """ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.vision_client = self._initialize_vision_client()
        self.max_image_size = int(os.getenv("MAX_IMAGE_SIZE", "10485760"))
        self.supported_formats = os.getenv("SUPPORTED_IMAGE_FORMATS", "jpg,jpeg,png,webp").split(",")
        self.confidence_threshold = float(os.getenv("VISION_CONFIDENCE_THRESHOLD", "0.7"))
    
    def _initialize_vision_client(self):
        """Google Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
            if credentials_path and os.path.exists(credentials_path):
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
            
            return vision.ImageAnnotatorClient()
        except Exception as e:
            logger.error(f"Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return None
    
    async def analyze_product_image(self, image_data: bytes) -> Dict[str, Any]:
        """ìƒí’ˆ ì´ë¯¸ì§€ ì¢…í•© ë¶„ì„"""
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = await self._preprocess_image(image_data)
            
            # ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ë¶„ì„ ìˆ˜í–‰
            tasks = [
                self._detect_objects(processed_image),
                self._detect_text(processed_image),
                self._detect_labels(processed_image),
                self._analyze_product_attributes(processed_image)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ í†µí•©
            analysis_result = {
                "objects": results[0] if not isinstance(results[0], Exception) else [],
                "text": results[1] if not isinstance(results[1], Exception) else [],
                "labels": results[2] if not isinstance(results[2], Exception) else [],
                "attributes": results[3] if not isinstance(results[3], Exception) else {},
                "product_info": {}
            }
            
            # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
            product_info = await self._extract_product_info(analysis_result)
            analysis_result["product_info"] = product_info
            
            return {
                "success": True,
                "analysis": analysis_result,
                "confidence": self._calculate_overall_confidence(analysis_result)
            }
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "analysis": {}
            }
    
    async def _preprocess_image(self, image_data: bytes) -> bytes:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # PILë¡œ ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(io.BytesIO(image_data))
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (Vision API ìµœì í™”)
            max_dimension = 1024
            if max(image.size) > max_dimension:
                ratio = max_dimension / max(image.size)
                new_size = tuple(int(dim * ratio) for dim in image.size)
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            # RGB ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
            image_array = np.array(image)
            enhanced_image = self._enhance_image_quality(image_array)
            
            # ë°”ì´íŠ¸ë¡œ ë³€í™˜
            enhanced_pil = Image.fromarray(enhanced_image)
            output_buffer = io.BytesIO()
            enhanced_pil.save(output_buffer, format='JPEG', quality=95)
            
            return output_buffer.getvalue()
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return image_data  # ì›ë³¸ ë°˜í™˜
    
    def _enhance_image_quality(self, image_array: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
        try:
            # ë…¸ì´ì¦ˆ ì œê±°
            denoised = cv2.bilateralFilter(image_array, 9, 75, 75)
            
            # ì„ ëª…ë„ í–¥ìƒ
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            sharpened = cv2.filter2D(denoised, -1, kernel)
            
            # ëŒ€ë¹„ í–¥ìƒ
            lab = cv2.cvtColor(sharpened, cv2.COLOR_RGB2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            enhanced = cv2.merge([l, a, b])
            enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)
            
            return enhanced
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {str(e)}")
            return image_array
    
    async def _detect_objects(self, image_data: bytes) -> List[Dict[str, Any]]:
        """ê°ì²´ ê°ì§€"""
        if not self.vision_client:
            return []
        
        try:
            image = vision.Image(content=image_data)
            response = self.vision_client.object_localization(image=image)
            
            objects = []
            for obj in response.localized_object_annotations:
                if obj.score >= self.confidence_threshold:
                    objects.append({
                        "name": obj.name,
                        "confidence": obj.score,
                        "bounding_box": {
                            "vertices": [
                                {"x": vertex.x, "y": vertex.y} 
                                for vertex in obj.bounding_poly.normalized_vertices
                            ]
                        }
                    })
            
            return objects
            
        except Exception as e:
            logger.error(f"ê°ì²´ ê°ì§€ ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _detect_text(self, image_data: bytes) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ê°ì§€ ë° OCR"""
        if not self.vision_client:
            return []
        
        try:
            image = vision.Image(content=image_data)
            response = self.vision_client.text_detection(image=image)
            
            texts = []
            for text in response.text_annotations:
                if text.description and len(text.description.strip()) > 1:
                    texts.append({
                        "text": text.description.strip(),
                        "confidence": getattr(text, 'confidence', 0.9),
                        "bounding_box": {
                            "vertices": [
                                {"x": vertex.x, "y": vertex.y} 
                                for vertex in text.bounding_poly.vertices
                            ]
                        }
                    })
            
            return texts
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ê°ì§€ ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _detect_labels(self, image_data: bytes) -> List[Dict[str, Any]]:
        """ë¼ë²¨ ê°ì§€"""
        if not self.vision_client:
            return []
        
        try:
            image = vision.Image(content=image_data)
            response = self.vision_client.label_detection(image=image)
            
            labels = []
            for label in response.label_annotations:
                if label.score >= self.confidence_threshold:
                    labels.append({
                        "description": label.description,
                        "confidence": label.score,
                        "topicality": getattr(label, 'topicality', 0.0)
                    })
            
            return labels
            
        except Exception as e:
            logger.error(f"ë¼ë²¨ ê°ì§€ ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _analyze_product_attributes(self, image_data: bytes) -> Dict[str, Any]:
        """ìƒí’ˆ ì†ì„± ë¶„ì„"""
        try:
            # ìƒ‰ìƒ ë¶„ì„
            colors = await self._analyze_colors(image_data)
            
            # ë¸Œëœë“œ ë¡œê³  ê°ì§€
            logos = await self._detect_logos(image_data)
            
            # ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ì¶”ì •
            category = await self._estimate_category(image_data)
            
            return {
                "colors": colors,
                "logos": logos,
                "estimated_category": category
            }
            
        except Exception as e:
            logger.error(f"ìƒí’ˆ ì†ì„± ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    async def _analyze_colors(self, image_data: bytes) -> List[Dict[str, Any]]:
        """ìƒ‰ìƒ ë¶„ì„"""
        try:
            image = Image.open(io.BytesIO(image_data))
            image_array = np.array(image)
            
            # ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ (K-means í´ëŸ¬ìŠ¤í„°ë§)
            pixels = image_array.reshape(-1, 3)
            
            # ìƒ˜í”Œë§ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
            if len(pixels) > 10000:
                indices = np.random.choice(len(pixels), 10000, replace=False)
                pixels = pixels[indices]
            
            from sklearn.cluster import KMeans
            kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
            kmeans.fit(pixels)
            
            colors = []
            for i, color in enumerate(kmeans.cluster_centers_):
                colors.append({
                    "rgb": [int(c) for c in color],
                    "hex": "#{:02x}{:02x}{:02x}".format(int(color[0]), int(color[1]), int(color[2])),
                    "percentage": float(np.sum(kmeans.labels_ == i) / len(kmeans.labels_))
                })
            
            # ë¹„ìœ¨ ìˆœìœ¼ë¡œ ì •ë ¬
            colors.sort(key=lambda x: x["percentage"], reverse=True)
            return colors
            
        except Exception as e:
            logger.error(f"ìƒ‰ìƒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _detect_logos(self, image_data: bytes) -> List[Dict[str, Any]]:
        """ë¡œê³  ê°ì§€"""
        if not self.vision_client:
            return []
        
        try:
            image = vision.Image(content=image_data)
            response = self.vision_client.logo_detection(image=image)
            
            logos = []
            for logo in response.logo_annotations:
                if logo.score >= self.confidence_threshold:
                    logos.append({
                        "description": logo.description,
                        "confidence": logo.score,
                        "bounding_box": {
                            "vertices": [
                                {"x": vertex.x, "y": vertex.y} 
                                for vertex in logo.bounding_poly.vertices
                            ]
                        }
                    })
            
            return logos
            
        except Exception as e:
            logger.error(f"ë¡œê³  ê°ì§€ ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _estimate_category(self, image_data: bytes) -> Dict[str, Any]:
        """ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ì¶”ì •"""
        try:
            # ê°„ë‹¨í•œ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ML ëª¨ë¸ ì‚¬ìš©)
            category_keywords = {
                "electronics": ["phone", "laptop", "computer", "tablet", "camera", "headphone"],
                "clothing": ["shirt", "dress", "pants", "shoes", "jacket", "hat"],
                "home": ["furniture", "lamp", "chair", "table", "bed", "sofa"],
                "beauty": ["cosmetics", "perfume", "makeup", "skincare"],
                "sports": ["ball", "equipment", "fitness", "sports"],
                "books": ["book", "magazine", "novel"],
                "toys": ["toy", "game", "doll", "puzzle"]
            }
            
            # ë¼ë²¨ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì¶”ì • (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
            return {
                "category": "general",
                "confidence": 0.5,
                "subcategories": []
            }
            
        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ ì¶”ì • ì‹¤íŒ¨: {str(e)}")
            return {}
    
    async def _extract_product_info(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
        try:
            product_info = {
                "name": "",
                "brand": "",
                "model": "",
                "category": "",
                "keywords": [],
                "confidence": 0.0
            }
            
            # í…ìŠ¤íŠ¸ì—ì„œ ìƒí’ˆëª…/ë¸Œëœë“œ ì¶”ì¶œ
            texts = analysis_result.get("text", [])
            if texts:
                # ê°€ì¥ í° í…ìŠ¤íŠ¸ë¥¼ ìƒí’ˆëª…ìœ¼ë¡œ ì¶”ì •
                main_text = max(texts, key=lambda x: len(x.get("text", "")))
                product_info["name"] = main_text.get("text", "")
            
            # ë¡œê³ ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ
            logos = analysis_result.get("attributes", {}).get("logos", [])
            if logos:
                product_info["brand"] = logos[0].get("description", "")
            
            # ë¼ë²¨ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            labels = analysis_result.get("labels", [])
            product_info["keywords"] = [
                label.get("description", "") 
                for label in labels[:5]  # ìƒìœ„ 5ê°œë§Œ
            ]
            
            # ì¹´í…Œê³ ë¦¬ ì„¤ì •
            category_info = analysis_result.get("attributes", {}).get("estimated_category", {})
            product_info["category"] = category_info.get("category", "general")
            
            # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
            product_info["confidence"] = self._calculate_overall_confidence(analysis_result)
            
            return product_info
            
        except Exception as e:
            logger.error(f"ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _calculate_overall_confidence(self, analysis_result: Dict[str, Any]) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            confidences = []
            
            # ê°ì²´ ê°ì§€ ì‹ ë¢°ë„
            objects = analysis_result.get("objects", [])
            if objects:
                obj_confidence = sum(obj.get("confidence", 0) for obj in objects) / len(objects)
                confidences.append(obj_confidence)
            
            # ë¼ë²¨ ê°ì§€ ì‹ ë¢°ë„
            labels = analysis_result.get("labels", [])
            if labels:
                label_confidence = sum(label.get("confidence", 0) for label in labels) / len(labels)
                confidences.append(label_confidence)
            
            # ë¡œê³  ê°ì§€ ì‹ ë¢°ë„
            logos = analysis_result.get("attributes", {}).get("logos", [])
            if logos:
                logo_confidence = sum(logo.get("confidence", 0) for logo in logos) / len(logos)
                confidences.append(logo_confidence)
            
            return sum(confidences) / len(confidences) if confidences else 0.0
            
        except Exception as e:
            logger.error(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return 0.0
```

### 7.3 ì´ë¯¸ì§€ ê²€ìƒ‰ ë„êµ¬

#### ì´ë¯¸ì§€ ê²€ìƒ‰ ë„êµ¬ (`src/agent/tools/image_search_tools.py`)
```python
from langchain.tools import BaseTool
from typing import Dict, Any, List, Optional
import asyncio
from pydantic import BaseModel, Field

from ..services.image_analysis import ImageAnalysisService
from .shopping_crawlers import MultiShoppingCrawler

class ImageSearchInput(BaseModel):
    """ì´ë¯¸ì§€ ê²€ìƒ‰ ì…ë ¥ ëª¨ë¸"""
    image_data: bytes = Field(description="ì´ë¯¸ì§€ ë°ì´í„°")
    additional_context: Optional[str] = Field(default="", description="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸")

class ImageProductSearchTool(BaseTool):
    """ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰ ë„êµ¬"""
    name = "image_product_search"
    description = "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìœ ì‚¬í•œ ìƒí’ˆì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    args_schema = ImageSearchInput
    
    def __init__(self):
        super().__init__()
        self.image_analyzer = ImageAnalysisService()
        self.shopping_crawler = MultiShoppingCrawler()
    
    def _run(self, image_data: bytes, additional_context: str = "") -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰"""
        return asyncio.run(self._arun(image_data, additional_context))
    
    async def _arun(self, image_data: bytes, additional_context: str = "") -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„
            analysis_result = await self.image_analyzer.analyze_product_image(image_data)
            
            if not analysis_result["success"]:
                return {
                    "success": False,
                    "error": "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    "details": analysis_result.get("error", "")
                }
            
            # 2ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_query = await self._generate_search_query(
                analysis_result["analysis"], 
                additional_context
            )
            
            # 3ë‹¨ê³„: ìƒí’ˆ ê²€ìƒ‰
            search_results = await self.shopping_crawler._arun(search_query, max_results=10)
            
            # 4ë‹¨ê³„: ê²°ê³¼ í•„í„°ë§ ë° ë­í‚¹
            filtered_results = await self._filter_and_rank_results(
                search_results.get("products", []),
                analysis_result["analysis"]
            )
            
            return {
                "success": True,
                "image_analysis": analysis_result["analysis"],
                "search_query": search_query,
                "products": filtered_results,
                "total_found": len(filtered_results),
                "confidence": analysis_result.get("confidence", 0.0)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "image_analysis": {},
                "products": []
            }
    
    async def _generate_search_query(
        self, 
        analysis: Dict[str, Any], 
        additional_context: str
    ) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        try:
            query_parts = []
            
            # ìƒí’ˆ ì •ë³´ì—ì„œ ì¿¼ë¦¬ ìƒì„±
            product_info = analysis.get("product_info", {})
            
            # ë¸Œëœë“œ ì¶”ê°€
            brand = product_info.get("brand", "")
            if brand:
                query_parts.append(brand)
            
            # ìƒí’ˆëª… ì¶”ê°€ (ì •ì œ)
            name = product_info.get("name", "")
            if name:
                # ìƒí’ˆëª…ì—ì„œ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°
                cleaned_name = self._clean_product_name(name)
                if cleaned_name:
                    query_parts.append(cleaned_name)
            
            # í‚¤ì›Œë“œ ì¶”ê°€
            keywords = product_info.get("keywords", [])
            relevant_keywords = [kw for kw in keywords[:3] if self._is_relevant_keyword(kw)]
            query_parts.extend(relevant_keywords)
            
            # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if additional_context:
                query_parts.append(additional_context)
            
            # ì¿¼ë¦¬ ì¡°í•©
            search_query = " ".join(query_parts)
            
            # ê¸°ë³¸ ì¿¼ë¦¬ê°€ ì—†ëŠ” ê²½ìš° ë¼ë²¨ ê¸°ë°˜ ìƒì„±
            if not search_query.strip():
                labels = analysis.get("labels", [])
                if labels:
                    search_query = labels[0].get("description", "ìƒí’ˆ")
            
            return search_query.strip() or "ìƒí’ˆ"
            
        except Exception as e:
            return "ìƒí’ˆ"
    
    def _clean_product_name(self, name: str) -> str:
        """ìƒí’ˆëª… ì •ì œ"""
        try:
            # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
            import re
            
            # íŠ¹ìˆ˜ë¬¸ì ì œê±°
            cleaned = re.sub(r'[^\w\sê°€-í£]', ' ', name)
            
            # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°
            stop_words = ['new', 'original', 'genuine', 'authentic', 'sale', 'discount']
            words = cleaned.split()
            filtered_words = [word for word in words if word.lower() not in stop_words]
            
            return " ".join(filtered_words[:5])  # ìµœëŒ€ 5ë‹¨ì–´
            
        except Exception:
            return name
    
    def _is_relevant_keyword(self, keyword: str) -> bool:
        """í‚¤ì›Œë“œ ê´€ë ¨ì„± í™•ì¸"""
        # ìƒí’ˆê³¼ ê´€ë ¨ ì—†ëŠ” ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ í•„í„°ë§
        irrelevant_keywords = [
            'product', 'item', 'thing', 'object', 'material', 'design',
            'color', 'white', 'black', 'red', 'blue', 'green'
        ]
        return keyword.lower() not in irrelevant_keywords and len(keyword) > 2
    
    async def _filter_and_rank_results(
        self, 
        products: List[Dict[str, Any]], 
        analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ ë° ë­í‚¹"""
        try:
            if not products:
                return []
            
            # ê° ìƒí’ˆì— ëŒ€í•´ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
            scored_products = []
            for product in products:
                similarity_score = await self._calculate_similarity_score(product, analysis)
                product_with_score = product.copy()
                product_with_score["similarity_score"] = similarity_score
                scored_products.append(product_with_score)
            
            # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì •ë ¬
            scored_products.sort(key=lambda x: x.get("similarity_score", 0), reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ë§Œ ë°˜í™˜
            return scored_products[:8]
            
        except Exception as e:
            return products[:8]  # ì—ëŸ¬ ì‹œ ì›ë³¸ ê²°ê³¼ ë°˜í™˜
    
    async def _calculate_similarity_score(
        self, 
        product: Dict[str, Any], 
        analysis: Dict[str, Any]
    ) -> float:
        """ìƒí’ˆê³¼ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ê°„ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°"""
        try:
            score = 0.0
            
            product_name = product.get("name", "").lower()
            product_info = analysis.get("product_info", {})
            
            # ë¸Œëœë“œ ë§¤ì¹­ (ê°€ì¤‘ì¹˜: 0.3)
            brand = product_info.get("brand", "").lower()
            if brand and brand in product_name:
                score += 0.3
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ (ê°€ì¤‘ì¹˜: 0.4)
            keywords = product_info.get("keywords", [])
            keyword_matches = sum(
                1 for keyword in keywords 
                if keyword.lower() in product_name
            )
            if keywords:
                score += 0.4 * (keyword_matches / len(keywords))
            
            # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (ê°€ì¤‘ì¹˜: 0.2)
            category = product_info.get("category", "")
            if category and category != "general":
                # ê°„ë‹¨í•œ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ë¡œì§
                if any(cat_word in product_name for cat_word in category.split()):
                    score += 0.2
            
            # ê°€ê²© í•©ë¦¬ì„± (ê°€ì¤‘ì¹˜: 0.1)
            price = product.get("price", 0)
            if 1000 <= price <= 10000000:  # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„
                score += 0.1
            
            return min(score, 1.0)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
            
        except Exception as e:
            return 0.0

class ImageSimilaritySearchTool(BaseTool):
    """ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ë„êµ¬"""
    name = "image_similarity_search"
    description = "ì´ë¯¸ì§€ì˜ ì‹œê°ì  íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒí’ˆì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    args_schema = ImageSearchInput
    
    def __init__(self):
        super().__init__()
        self.image_analyzer = ImageAnalysisService()
    
    def _run(self, image_data: bytes, additional_context: str = "") -> Dict[str, Any]:
        return asyncio.run(self._arun(image_data, additional_context))
    
    async def _arun(self, image_data: bytes, additional_context: str = "") -> Dict[str, Any]:
        """ì‹œê°ì  ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰"""
        try:
            # ì´ë¯¸ì§€ ë¶„ì„
            analysis_result = await self.image_analyzer.analyze_product_image(image_data)
            
            if not analysis_result["success"]:
                return {
                    "success": False,
                    "error": "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            # ìƒ‰ìƒ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            colors = analysis_result["analysis"].get("attributes", {}).get("colors", [])
            color_query = self._generate_color_query(colors)
            
            # í˜•íƒœ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            objects = analysis_result["analysis"].get("objects", [])
            shape_query = self._generate_shape_query(objects)
            
            # í†µí•© ì¿¼ë¦¬ ìƒì„±
            visual_query = f"{color_query} {shape_query}".strip()
            
            return {
                "success": True,
                "visual_query": visual_query,
                "color_analysis": colors,
                "shape_analysis": objects,
                "recommendation": f"'{visual_query}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _generate_color_query(self, colors: List[Dict[str, Any]]) -> str:
        """ìƒ‰ìƒ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±"""
        if not colors:
            return ""
        
        # ì£¼ìš” ìƒ‰ìƒ (30% ì´ìƒ)
        main_colors = [
            color for color in colors 
            if color.get("percentage", 0) > 0.3
        ]
        
        if main_colors:
            # ìƒ‰ìƒëª… ë§¤í•‘ (ê°„ë‹¨í•œ ë²„ì „)
            color_names = {
                "red": "ë¹¨ê°„",
                "blue": "íŒŒë€",
                "green": "ì´ˆë¡",
                "yellow": "ë…¸ë€",
                "black": "ê²€ì€",
                "white": "í°",
                "gray": "íšŒìƒ‰",
                "brown": "ê°ˆìƒ‰"
            }
            
            # RGB ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒ‰ìƒëª… ì¶”ì • (ê°„ë‹¨í•œ ë¡œì§)
            main_color = main_colors[0]
            rgb = main_color.get("rgb", [0, 0, 0])
            
            if max(rgb) < 50:
                return "ê²€ì€ìƒ‰"
            elif min(rgb) > 200:
                return "í°ìƒ‰"
            elif rgb[0] > rgb[1] and rgb[0] > rgb[2]:
                return "ë¹¨ê°„ìƒ‰"
            elif rgb[1] > rgb[0] and rgb[1] > rgb[2]:
                return "ì´ˆë¡ìƒ‰"
            elif rgb[2] > rgb[0] and rgb[2] > rgb[1]:
                return "íŒŒë€ìƒ‰"
        
        return ""
    
    def _generate_shape_query(self, objects: List[Dict[str, Any]]) -> str:
        """í˜•íƒœ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±"""
        if not objects:
            return ""
        
        # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ê°ì²´
        main_object = max(objects, key=lambda x: x.get("confidence", 0))
        object_name = main_object.get("name", "")
        
        # ê°ì²´ëª…ì„ í•œêµ­ì–´ë¡œ ë§¤í•‘ (ê°„ë‹¨í•œ ë²„ì „)
        object_mapping = {
            "Mobile phone": "íœ´ëŒ€í°",
            "Laptop": "ë…¸íŠ¸ë¶",
            "Clothing": "ì˜ë¥˜",
            "Footwear": "ì‹ ë°œ",
            "Bag": "ê°€ë°©",
            "Watch": "ì‹œê³„",
            "Sunglasses": "ì„ ê¸€ë¼ìŠ¤"
        }
        
        return object_mapping.get(object_name, object_name)

def get_image_search_tools() -> List[BaseTool]:
    """ì´ë¯¸ì§€ ê²€ìƒ‰ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    return [
        ImageProductSearchTool(),
        ImageSimilaritySearchTool()
    ]
```

### 7.4 Agent ì›Œí¬í”Œë¡œìš° ì—…ë°ì´íŠ¸

#### ì´ë¯¸ì§€ ê²€ìƒ‰ ì›Œí¬í”Œë¡œìš° (`src/agent/workflows/image_search_workflow.py`)
```python
from typing import Dict, Any, List
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolExecutor

from ..models.agent_models import AgentState
from ..tools.image_search_tools import get_image_search_tools

def create_image_search_workflow(llm, tool_executor: ToolExecutor) -> StateGraph:
    """ì´ë¯¸ì§€ ê²€ìƒ‰ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    
    workflow = StateGraph(AgentState)
    
    # ë…¸ë“œ ì •ì˜
    workflow.add_node("analyze_image", analyze_image_node)
    workflow.add_node("generate_search_query", generate_search_query_node)
    workflow.add_node("search_products", search_products_node)
    workflow.add_node("rank_results", rank_results_node)
    workflow.add_node("generate_response", generate_response_node)
    
    # ì—£ì§€ ì •ì˜
    workflow.set_entry_point("analyze_image")
    workflow.add_edge("analyze_image", "generate_search_query")
    workflow.add_edge("generate_search_query", "search_products")
    workflow.add_edge("search_products", "rank_results")
    workflow.add_edge("rank_results", "generate_response")
    workflow.add_edge("generate_response", END)
    
    return workflow

async def analyze_image_node(state: AgentState) -> AgentState:
    """ì´ë¯¸ì§€ ë¶„ì„ ë…¸ë“œ"""
    try:
        # ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
        image_data = state.get("image_data")
        if not image_data:
            state["error"] = "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            return state
        
        # ì´ë¯¸ì§€ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
        from ..tools.image_search_tools import ImageProductSearchTool
        image_tool = ImageProductSearchTool()
        
        # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
        analysis_result = await image_tool._arun(
            image_data=image_data,
            additional_context=state.get("user_query", "")
        )
        
        state["image_analysis"] = analysis_result
        state["current_step"] = "image_analyzed"
        
        return state
        
    except Exception as e:
        state["error"] = f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        return state

async def generate_search_query_node(state: AgentState) -> AgentState:
    """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë…¸ë“œ"""
    try:
        analysis_result = state.get("image_analysis", {})
        
        if not analysis_result.get("success", False):
            state["error"] = "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            return state
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ì¶œ
        search_query = analysis_result.get("search_query", "")
        
        # ì‚¬ìš©ì ì¶”ê°€ ì…ë ¥ê³¼ ê²°í•©
        user_query = state.get("user_query", "")
        if user_query and user_query not in search_query:
            search_query = f"{search_query} {user_query}".strip()
        
        state["search_query"] = search_query
        state["current_step"] = "query_generated"
        
        return state
        
    except Exception as e:
        state["error"] = f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
        return state

async def search_products_node(state: AgentState) -> AgentState:
    """ìƒí’ˆ ê²€ìƒ‰ ë…¸ë“œ"""
    try:
        search_query = state.get("search_query", "")
        
        if not search_query:
            state["error"] = "ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
            return state
        
        # ë‹¤ì¤‘ ì‡¼í•‘ëª° ê²€ìƒ‰
        from ..tools.shopping_crawlers import MultiShoppingCrawler
        crawler = MultiShoppingCrawler()
        
        search_results = await crawler._arun(search_query, max_results=15)
        
        state["search_results"] = search_results.get("products", [])
        state["current_step"] = "products_searched"
        
        return state
        
    except Exception as e:
        state["error"] = f"ìƒí’ˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        return state

async def rank_results_node(state: AgentState) -> AgentState:
    """ê²°ê³¼ ë­í‚¹ ë…¸ë“œ"""
    try:
        search_results = state.get("search_results", [])
        image_analysis = state.get("image_analysis", {})
        
        if not search_results:
            state["ranked_results"] = []
            return state
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
        from ..tools.image_search_tools import ImageProductSearchTool
        image_tool = ImageProductSearchTool()
        
        analysis_data = image_analysis.get("image_analysis", {})
        ranked_results = await image_tool._filter_and_rank_results(
            search_results, 
            analysis_data
        )
        
        state["ranked_results"] = ranked_results
        state["current_step"] = "results_ranked"
        
        return state
        
    except Exception as e:
        state["error"] = f"ê²°ê³¼ ë­í‚¹ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        state["ranked_results"] = state.get("search_results", [])
        return state

async def generate_response_node(state: AgentState) -> AgentState:
    """ì‘ë‹µ ìƒì„± ë…¸ë“œ"""
    try:
        ranked_results = state.get("ranked_results", [])
        image_analysis = state.get("image_analysis", {})
        search_query = state.get("search_query", "")
        
        # ì‘ë‹µ ë©”ì‹œì§€ ìƒì„±
        if ranked_results:
            response_message = f"""
ğŸ” **ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼**

ğŸ“¸ **ê°ì§€ëœ ìƒí’ˆ ì •ë³´:**
- ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_query}
- ì‹ ë¢°ë„: {image_analysis.get('confidence', 0.0):.1%}

ğŸ›’ **ìœ ì‚¬ ìƒí’ˆ {len(ranked_results)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!**

ê°€ì¥ ìœ ì‚¬í•œ ìƒí’ˆë“¤ì„ ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í–ˆìŠµë‹ˆë‹¤. 
ì´ë¯¸ì§€ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ìƒí’ˆë¶€í„° í™•ì¸í•´ë³´ì„¸ìš”.
            """
        else:
            response_message = f"""
ğŸ” **ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼**

ğŸ“¸ ì´ë¯¸ì§€ì—ì„œ ìƒí’ˆì„ ë¶„ì„í–ˆì§€ë§Œ, ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ **ì¶”ì²œ ë°©ë²•:**
- ë” ëª…í™•í•œ ìƒí’ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”
- ìƒí’ˆëª…ì„ ì§ì ‘ ì…ë ¥í•´ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”
- ë¸Œëœë“œëª…ì´ë‚˜ ëª¨ë¸ëª…ì„ í•¨ê»˜ ì…ë ¥í•´ë³´ì„¸ìš”

ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_query}
            """
        
        # ìµœì¢… ë©”ì‹œì§€ ì¶”ê°€
        final_message = AIMessage(content=response_message)
        state["messages"].append(final_message)
        
        state["current_step"] = "completed"
        state["final_response"] = response_message
        
        return state
        
    except Exception as e:
        error_message = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        error_ai_message = AIMessage(content=error_message)
        state["messages"].append(error_ai_message)
        state["error"] = str(e)
        return state
```

### 7.5 ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸

#### ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¬ë° ì—…ë°ì´íŠ¸ (`src/api/services/streaming.py` ì¶”ê°€)
```python
# ê¸°ì¡´ StreamingService í´ë˜ìŠ¤ì— ì¶”ê°€

async def stream_image_response(
    self,
    image_data: bytes,
    message: str,
    session_id: str
) -> AsyncGenerator[str, None]:
    """ì´ë¯¸ì§€ ê²€ìƒ‰ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì—…ë°ì´íŠ¸ëœ ë²„ì „)"""
    
    try:
        # ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘
        yield await self._send_event("image_analysis_start", {
            "message": "ğŸ“¸ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            "step": "image_processing"
        }, session_id)
        
        # ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        from ...agent.services.image_analysis import ImageAnalysisService
        image_analyzer = ImageAnalysisService()
        
        # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
        analysis_result = await image_analyzer.analyze_product_image(image_data)
        
        if analysis_result["success"]:
            # ë¶„ì„ ì™„ë£Œ
            yield await self._send_event("image_analysis_complete", {
                "message": "âœ… ì´ë¯¸ì§€ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
                "analysis": analysis_result["analysis"],
                "confidence": analysis_result.get("confidence", 0.0)
            }, session_id)
            
            # ìƒí’ˆ ê²€ìƒ‰ ì‹œì‘
            yield await self._send_event("product_search_start", {
                "message": "ğŸ” ìœ ì‚¬í•œ ìƒí’ˆì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "step": "product_search"
            }, session_id)
            
            # ì´ë¯¸ì§€ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
            from ...agent.tools.image_search_tools import ImageProductSearchTool
            image_search_tool = ImageProductSearchTool()
            
            search_result = await image_search_tool._arun(image_data, message)
            
            if search_result["success"] and search_result["products"]:
                # ê²€ìƒ‰ ê²°ê³¼ ì „ì†¡
                yield await self._send_event("search_results", {
                    "message": f"ğŸ‰ {len(search_result['products'])}ê°œì˜ ìœ ì‚¬ ìƒí’ˆì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!",
                    "products": search_result["products"],
                    "search_query": search_result.get("search_query", ""),
                    "total_found": search_result.get("total_found", 0)
                }, session_id)
                
                # ìµœì¢… ì¶”ì²œ
                best_match = search_result["products"][0] if search_result["products"] else None
                if best_match:
                    yield await self._send_event("recommendation", {
                        "message": "ğŸ† ê°€ì¥ ìœ ì‚¬í•œ ìƒí’ˆì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!",
                        "best_match": best_match,
                        "similarity_score": best_match.get("similarity_score", 0.0)
                    }, session_id)
            else:
                # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
                yield await self._send_event("no_results", {
                    "message": "ğŸ˜” ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    "suggestions": [
                        "ë” ëª…í™•í•œ ìƒí’ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”",
                        "ìƒí’ˆëª…ì„ ì§ì ‘ ì…ë ¥í•´ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”",
                        "ë¸Œëœë“œëª…ì´ë‚˜ ëª¨ë¸ëª…ì„ í•¨ê»˜ ì…ë ¥í•´ë³´ì„¸ìš”"
                    ]
                }, session_id)
        else:
            # ë¶„ì„ ì‹¤íŒ¨
            yield await self._send_event("analysis_failed", {
                "message": "âŒ ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "error": analysis_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
                "suggestions": [
                    "ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”",
                    "ì´ë¯¸ì§€ê°€ ì„ ëª…í•œì§€ í™•ì¸í•´ë³´ì„¸ìš”",
                    "ìƒí’ˆì´ ëª…í™•íˆ ë³´ì´ëŠ” ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”"
                ]
            }, session_id)
        
    except Exception as e:
        yield await self._send_event("error", {
            "message": "ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "error": str(e),
            "error_type": "image_processing_error"
        }, session_id)
    
    finally:
        yield await self._send_event("complete", {
            "message": "ì´ë¯¸ì§€ ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "session_id": session_id
        }, session_id)
```

### 7.6 í…ŒìŠ¤íŠ¸ ì½”ë“œ

#### ì´ë¯¸ì§€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (`tests/test_agent/test_image_search.py`)
```python
import pytest
import asyncio
import io
from PIL import Image
import numpy as np

from src.agent.services.image_analysis import ImageAnalysisService
from src.agent.tools.image_search_tools import ImageProductSearchTool

@pytest.fixture
def sample_image_data():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±"""
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    image = Image.new('RGB', (300, 300), color='red')
    buffer = io.BytesIO()
    image.save(buffer, format='JPEG')
    return buffer.getvalue()

@pytest.fixture
def image_analysis_service():
    return ImageAnalysisService()

@pytest.fixture
def image_search_tool():
    return ImageProductSearchTool()

@pytest.mark.asyncio
async def test_image_analysis_service(image_analysis_service, sample_image_data):
    """ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    result = await image_analysis_service.analyze_product_image(sample_image_data)
    
    assert "success" in result
    if result["success"]:
        assert "analysis" in result
        assert "confidence" in result
        
        analysis = result["analysis"]
        assert "product_info" in analysis
        assert "objects" in analysis
        assert "labels" in analysis

@pytest.mark.asyncio
async def test_image_search_tool(image_search_tool, sample_image_data):
    """ì´ë¯¸ì§€ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸"""
    result = await image_search_tool._arun(sample_image_data, "í…ŒìŠ¤íŠ¸ ìƒí’ˆ")
    
    assert "success" in result
    assert "products" in result
    assert "search_query" in result
    
    if result["success"]:
        assert isinstance(result["products"], list)

def test_image_preprocessing(image_analysis_service, sample_image_data):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    processed = asyncio.run(
        image_analysis_service._preprocess_image(sample_image_data)
    )
    
    assert isinstance(processed, bytes)
    assert len(processed) > 0

@pytest.mark.asyncio
async def test_search_query_generation(image_search_tool):
    """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
    mock_analysis = {
        "product_info": {
            "brand": "Apple",
            "name": "iPhone 15 Pro",
            "keywords": ["phone", "smartphone", "mobile"]
        }
    }
    
    query = await image_search_tool._generate_search_query(mock_analysis, "ìµœì‹ ")
    
    assert isinstance(query, str)
    assert len(query) > 0
    assert "Apple" in query or "iPhone" in query

def test_similarity_score_calculation(image_search_tool):
    """ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    mock_product = {
        "name": "Apple iPhone 15 Pro 256GB",
        "price": 1500000
    }
    
    mock_analysis = {
        "product_info": {
            "brand": "Apple",
            "keywords": ["iPhone", "smartphone"]
        }
    }
    
    score = asyncio.run(
        image_search_tool._calculate_similarity_score(mock_product, mock_analysis)
    )
    
    assert isinstance(score, float)
    assert 0.0 <= score <= 1.0

@pytest.mark.asyncio
async def test_color_analysis(image_analysis_service, sample_image_data):
    """ìƒ‰ìƒ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    colors = await image_analysis_service._analyze_colors(sample_image_data)
    
    assert isinstance(colors, list)
    if colors:
        color = colors[0]
        assert "rgb" in color
        assert "hex" in color
        assert "percentage" in color

def test_product_name_cleaning(image_search_tool):
    """ìƒí’ˆëª… ì •ì œ í…ŒìŠ¤íŠ¸"""
    dirty_name = "New!!! Apple iPhone 15 Pro @@@ Original Authentic Sale!!!"
    cleaned = image_search_tool._clean_product_name(dirty_name)
    
    assert "Apple" in cleaned
    assert "iPhone" in cleaned
    assert "!!!" not in cleaned
    assert "@@@" not in cleaned

def test_keyword_relevance(image_search_tool):
    """í‚¤ì›Œë“œ ê´€ë ¨ì„± í…ŒìŠ¤íŠ¸"""
    assert image_search_tool._is_relevant_keyword("smartphone") == True
    assert image_search_tool._is_relevant_keyword("iPhone") == True
    assert image_search_tool._is_relevant_keyword("color") == False
    assert image_search_tool._is_relevant_keyword("a") == False
```

## âœ… ì™„ë£Œ ê¸°ì¤€
- [ ] Google Vision API ì—°ë™ ì™„ë£Œ
- [ ] ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ êµ¬í˜„ (ê°ì²´, í…ìŠ¤íŠ¸, ë¼ë²¨, ë¡œê³  ê°ì§€)
- [ ] ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° í’ˆì§ˆ í–¥ìƒ êµ¬í˜„
- [ ] ìƒ‰ìƒ ë¶„ì„ ë° ì‹œê°ì  íŠ¹ì„± ì¶”ì¶œ
- [ ] ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ê²€ìƒ‰ ë„êµ¬ êµ¬í˜„
- [ ] ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„± ê¸°ëŠ¥
- [ ] ìœ ì‚¬ë„ ê¸°ë°˜ ê²°ê³¼ ë­í‚¹ ì‹œìŠ¤í…œ
- [ ] ì´ë¯¸ì§€ ê²€ìƒ‰ ì›Œí¬í”Œë¡œìš° êµ¬í˜„
- [ ] ìŠ¤íŠ¸ë¦¬ë° APIì— ì´ë¯¸ì§€ ê²€ìƒ‰ í†µí•©
- [ ] í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ì´ë¯¸ì§€ ë¶„ì„ í…ŒìŠ¤íŠ¸
```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/test_agent/test_image_search.py -v

# ê°œë³„ í…ŒìŠ¤íŠ¸
pytest tests/test_agent/test_image_search.py::test_image_analysis_service -v
```

### 2. ì‹¤ì œ ì´ë¯¸ì§€ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
```bash
# ì„œë²„ ì‹¤í–‰
python scripts/run_api.py

# ì´ë¯¸ì§€ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/api/v1/chat/image \
  -F "message=ì´ ìƒí’ˆê³¼ ë¹„ìŠ·í•œ ê²ƒì„ ì°¾ì•„ì£¼ì„¸ìš”" \
  -F "session_id=test-session" \
  -F "image=@test_product.jpg"
```

### 3. Streamlit UIì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
```bash
# Streamlit ì•± ì‹¤í–‰
streamlit run src/ui/streamlit_app.py

# ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì´ë¯¸ì§€ ì—…ë¡œë“œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
```

## ğŸ”— ë‹¤ìŒ ë‹¨ê³„
[Phase 3 Step 8 - ì„±ëŠ¥ ìµœì í™” ë° ìºì‹±](mdc:.cursor/rules/tasks/phase3-step8-optimization.mdc)

## ğŸ“š ì°¸ê³  ë¬¸ì„œ
- [ê°œë°œ íƒœìŠ¤í¬ ê³„íš](mdc:.cursor/rules/development-task-plan.mdc)
- [ê¸°ìˆ  ì•„í‚¤í…ì²˜](mdc:.cursor/rules/technical-architecture.mdc)
- [Google Vision API ë¬¸ì„œ](https://cloud.google.com/vision/docs)

