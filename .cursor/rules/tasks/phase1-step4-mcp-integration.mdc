---
description:
globs:
alwaysApply: false
---
# 4ë‹¨ê³„: MCP ì—°ë™

## ğŸ¯ ëª©í‘œ
ë„êµ¬ í†µí•© ì‹œìŠ¤í…œ êµ¬ì¶• ë° langchain-mcp-adaptersë¥¼ í†µí•œ LangGraph Agentì™€ MCP ë„êµ¬ ì—°ë™

## ğŸ“‹ ìƒì„¸ íƒœìŠ¤í¬

### 4.1 MCP í™˜ê²½ ì„¤ì •

#### requirements.txt ì—…ë°ì´íŠ¸
```txt
# ê¸°ì¡´ ì˜ì¡´ì„±...

# MCP Integration
langchain-mcp-adapters==0.1.0
mcp-client==0.1.0

# Web Scraping & Browser
playwright==1.40.0
beautifulsoup4==4.12.2
requests==2.31.0
selenium==4.15.0

# Additional utilities
aiohttp==3.9.1
```

#### í™˜ê²½ ë³€ìˆ˜ ì—…ë°ì´íŠ¸ (`.env.example`)
```env
# ê¸°ì¡´ í™˜ê²½ë³€ìˆ˜...

# MCP Configuration
MCP_SERVER_URL=localhost:3000
MCP_TIMEOUT=30

# Browser Configuration
BROWSER_HEADLESS=true
BROWSER_TIMEOUT=10

# Search Configuration
MAX_SEARCH_RESULTS=10
SEARCH_TIMEOUT=30
```

### 4.2 MCP ë„êµ¬ ì„¤ì •

#### MCP ì–´ëŒ‘í„° ì„¤ì • (`src/agent/mcp/adapter.py`)
```python
import asyncio
import os
from typing import List, Dict, Any, Optional
from langchain_mcp_adapters import MCPAdapter
from langchain.tools import BaseTool

class MCPToolAdapter:
    """MCP ë„êµ¬ ì–´ëŒ‘í„° í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.mcp_adapter = None
        self.tools = []
        self._initialize_adapter()
    
    def _initialize_adapter(self):
        """MCP ì–´ëŒ‘í„° ì´ˆê¸°í™”"""
        try:
            server_url = os.getenv("MCP_SERVER_URL", "localhost:3000")
            timeout = int(os.getenv("MCP_TIMEOUT", "30"))
            
            self.mcp_adapter = MCPAdapter(
                server_url=server_url,
                timeout=timeout
            )
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¡œë“œ
            self._load_tools()
            
        except Exception as e:
            print(f"MCP ì–´ëŒ‘í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ë„êµ¬ ì‚¬ìš©
            self._load_fallback_tools()
    
    def _load_tools(self):
        """MCP ì„œë²„ì—ì„œ ë„êµ¬ ë¡œë“œ"""
        try:
            # MCP ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            available_tools = self.mcp_adapter.list_tools()
            
            # í•„ìš”í•œ ë„êµ¬ë“¤ë§Œ í•„í„°ë§
            required_tools = [
                "web_search",
                "browser_navigate", 
                "extract_content",
                "price_scraper"
            ]
            
            for tool_name in required_tools:
                if tool_name in available_tools:
                    tool = self.mcp_adapter.get_tool(tool_name)
                    self.tools.append(tool)
                    
        except Exception as e:
            print(f"MCP ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._load_fallback_tools()
    
    def _load_fallback_tools(self):
        """í´ë°± ë„êµ¬ ë¡œë“œ"""
        from ..tools.search_tools import get_basic_tools
        self.tools = get_basic_tools()
    
    def get_tools(self) -> List[BaseTool]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        return self.tools
    
    async def close(self):
        """MCP ì—°ê²° ì¢…ë£Œ"""
        if self.mcp_adapter:
            await self.mcp_adapter.close()
```

#### ì›¹ ê²€ìƒ‰ ë„êµ¬ (`src/agent/tools/web_search_tools.py`)
```python
from langchain.tools import BaseTool
from typing import List, Dict, Any, Optional
import asyncio
import aiohttp
from bs4 import BeautifulSoup
from pydantic import BaseModel, Field
import re

class WebSearchInput(BaseModel):
    """ì›¹ ê²€ìƒ‰ ì…ë ¥ ëª¨ë¸"""
    query: str = Field(description="ê²€ìƒ‰í•  í‚¤ì›Œë“œ")
    site: Optional[str] = Field(default=None, description="íŠ¹ì • ì‚¬ì´íŠ¸ ê²€ìƒ‰ (ì˜ˆ: coupang.com)")
    max_results: int = Field(default=10, description="ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜")

class WebSearchTool(BaseTool):
    """ì›¹ ê²€ìƒ‰ ë„êµ¬"""
    name = "web_search"
    description = "ì¸í„°ë„·ì—ì„œ ìƒí’ˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    args_schema = WebSearchInput
    
    def _run(self, query: str, site: Optional[str] = None, max_results: int = 10) -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰"""
        return asyncio.run(self._arun(query, site, max_results))
    
    async def _arun(self, query: str, site: Optional[str] = None, max_results: int = 10) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì›¹ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            search_query = query
            if site:
                search_query = f"site:{site} {query}"
            
            # ì—¬ëŸ¬ ì‡¼í•‘ëª°ì—ì„œ ê²€ìƒ‰
            shopping_sites = [
                "coupang.com",
                "11st.co.kr", 
                "gmarket.co.kr",
                "auction.co.kr",
                "shopping.naver.com"
            ]
            
            all_results = []
            
            for site in shopping_sites:
                site_query = f"site:{site} {query}"
                results = await self._search_site(site_query, max_results // len(shopping_sites))
                all_results.extend(results)
            
            return {
                "query": query,
                "total_results": len(all_results),
                "results": all_results[:max_results],
                "search_sites": shopping_sites
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "query": query,
                "results": []
            }
    
    async def _search_site(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê° ì‡¼í•‘ëª°ì˜ API ë˜ëŠ” í¬ë¡¤ë§ ë¡œì§ ì‚¬ìš©
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë°˜í™˜
        
        await asyncio.sleep(0.5)  # ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
        
        # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        mock_results = []
        for i in range(min(max_results, 3)):
            mock_results.append({
                "title": f"{query} ê²€ìƒ‰ ê²°ê³¼ {i+1}",
                "url": f"https://example.com/product{i+1}",
                "price": 150000 + (i * 10000),
                "shop": query.split(':')[1].split()[0] if 'site:' in query else "Unknown",
                "description": f"{query} ìƒí’ˆ ì„¤ëª… {i+1}",
                "image_url": f"https://example.com/image{i+1}.jpg"
            })
        
        return mock_results

class BrowserNavigateInput(BaseModel):
    """ë¸Œë¼ìš°ì € ë„¤ë¹„ê²Œì´ì…˜ ì…ë ¥ ëª¨ë¸"""
    url: str = Field(description="ë°©ë¬¸í•  URL")
    wait_for: Optional[str] = Field(default=None, description="ëŒ€ê¸°í•  CSS ì„ íƒì")

class BrowserNavigateTool(BaseTool):
    """ë¸Œë¼ìš°ì € ë„¤ë¹„ê²Œì´ì…˜ ë„êµ¬"""
    name = "browser_navigate"
    description = "ì›¹ ë¸Œë¼ìš°ì €ë¡œ íŠ¹ì • í˜ì´ì§€ì— ì ‘ì†í•˜ì—¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
    args_schema = BrowserNavigateInput
    
    def _run(self, url: str, wait_for: Optional[str] = None) -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰"""
        return asyncio.run(self._arun(url, wait_for))
    
    async def _arun(self, url: str, wait_for: Optional[str] = None) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ë¸Œë¼ìš°ì € ë„¤ë¹„ê²Œì´ì…˜"""
        try:
            # Playwright ë˜ëŠ” Seleniumì„ ì‚¬ìš©í•œ ë¸Œë¼ìš°ì € ìë™í™”
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ êµ¬í˜„
            
            await asyncio.sleep(1)  # í˜ì´ì§€ ë¡œë”© ì‹œë®¬ë ˆì´ì…˜
            
            # ì‹œë®¬ë ˆì´ì…˜ í˜ì´ì§€ ì •ë³´
            page_info = {
                "url": url,
                "title": "ìƒí’ˆ í˜ì´ì§€",
                "content": "ìƒí’ˆ ìƒì„¸ ì •ë³´...",
                "price": 150000,
                "availability": "ì¬ê³  ìˆìŒ",
                "rating": 4.5,
                "review_count": 1234,
                "images": ["image1.jpg", "image2.jpg"],
                "description": "ìƒí’ˆ ìƒì„¸ ì„¤ëª…..."
            }
            
            return {
                "success": True,
                "page_info": page_info,
                "url": url
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "url": url
            }

class ExtractContentInput(BaseModel):
    """ì½˜í…ì¸  ì¶”ì¶œ ì…ë ¥ ëª¨ë¸"""
    html: str = Field(description="HTML ì½˜í…ì¸ ")
    selectors: Dict[str, str] = Field(description="ì¶”ì¶œí•  ìš”ì†Œì˜ CSS ì„ íƒì")

class ExtractContentTool(BaseTool):
    """ì½˜í…ì¸  ì¶”ì¶œ ë„êµ¬"""
    name = "extract_content"
    description = "HTMLì—ì„œ íŠ¹ì • ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
    args_schema = ExtractContentInput
    
    def _run(self, html: str, selectors: Dict[str, str]) -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰"""
        return asyncio.run(self._arun(html, selectors))
    
    async def _arun(self, html: str, selectors: Dict[str, str]) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì½˜í…ì¸  ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            extracted_data = {}
            
            for key, selector in selectors.items():
                elements = soup.select(selector)
                if elements:
                    if len(elements) == 1:
                        extracted_data[key] = elements[0].get_text(strip=True)
                    else:
                        extracted_data[key] = [elem.get_text(strip=True) for elem in elements]
                else:
                    extracted_data[key] = None
            
            return {
                "success": True,
                "extracted_data": extracted_data
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

def get_mcp_tools() -> List[BaseTool]:
    """MCP ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    return [
        WebSearchTool(),
        BrowserNavigateTool(),
        ExtractContentTool()
    ]
```

### 4.3 Agent ì½”ì–´ ì—…ë°ì´íŠ¸

#### Agent ì½”ì–´ MCP ì—°ë™ (`src/agent/core.py` ì—…ë°ì´íŠ¸)
```python
import os
from typing import Dict, Any, List, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolExecutor
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from pydantic import BaseModel, Field

from .mcp.adapter import MCPToolAdapter
from .tools.web_search_tools import get_mcp_tools

class PriceFinderAgent:
    """ìµœì €ê°€ ì‡¼í•‘ Agent ë©”ì¸ í´ë˜ìŠ¤ (MCP ì—°ë™)"""
    
    def __init__(self):
        self.llm = self._setup_llm()
        self.mcp_adapter = MCPToolAdapter()
        self.tools = self._setup_tools()
        self.tool_executor = ToolExecutor(self.tools)
        self.workflow = self._create_workflow()
        self.app = self.workflow.compile()
    
    def _setup_llm(self) -> ChatGoogleGenerativeAI:
        """Gemini LLM ì„¤ì •"""
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        return ChatGoogleGenerativeAI(
            model=os.getenv("GEMINI_MODEL", "gemini-2.0-flash-exp"),
            google_api_key=api_key,
            temperature=0.1,
            max_tokens=2048
        )
    
    def _setup_tools(self) -> List:
        """ë„êµ¬ ì„¤ì • (MCP ë„êµ¬ ìš°ì„ , í´ë°±ìœ¼ë¡œ ê¸°ë³¸ ë„êµ¬)"""
        try:
            # MCP ë„êµ¬ ì‚¬ìš© ì‹œë„
            mcp_tools = self.mcp_adapter.get_tools()
            if mcp_tools:
                print(f"MCP ë„êµ¬ {len(mcp_tools)}ê°œ ë¡œë“œë¨")
                return mcp_tools
        except Exception as e:
            print(f"MCP ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # í´ë°±: ê¸°ë³¸ ì›¹ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
        print("ê¸°ë³¸ ì›¹ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©")
        return get_mcp_tools()
    
    def _create_workflow(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        from .workflows.search_workflow import create_search_workflow
        return create_search_workflow(self.llm, self.tool_executor)
    
    async def process_message(self, message: str, session_id: str) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ì²˜ë¦¬ ë©”ì¸ ë©”ì„œë“œ"""
        from .models.agent_models import AgentState
        
        initial_state = AgentState(
            messages=[HumanMessage(content=message)],
            user_query=message,
            session_id=session_id,
            current_step="start"
        )
        
        try:
            result = await self.app.ainvoke(initial_state)
            return {
                "success": True,
                "result": result,
                "session_id": session_id,
                "tools_used": [tool.name for tool in self.tools]
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id
            }
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.mcp_adapter:
            await self.mcp_adapter.close()
```

### 4.4 ì‹¤ì œ ì‡¼í•‘ëª° í¬ë¡¤ë§ ë„êµ¬

#### ì‡¼í•‘ëª°ë³„ í¬ë¡¤ëŸ¬ (`src/agent/tools/shopping_crawlers.py`)
```python
from langchain.tools import BaseTool
from typing import List, Dict, Any, Optional
import asyncio
import aiohttp
from bs4 import BeautifulSoup
from pydantic import BaseModel, Field
import re
from urllib.parse import urljoin, quote

class ShoppingCrawlerInput(BaseModel):
    """ì‡¼í•‘ëª° í¬ë¡¤ëŸ¬ ì…ë ¥ ëª¨ë¸"""
    query: str = Field(description="ê²€ìƒ‰í•  ìƒí’ˆëª…")
    max_results: int = Field(default=5, description="ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜")

class CoupangCrawler(BaseTool):
    """ì¿ íŒ¡ í¬ë¡¤ëŸ¬"""
    name = "coupang_search"
    description = "ì¿ íŒ¡ì—ì„œ ìƒí’ˆì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    args_schema = ShoppingCrawlerInput
    
    def _run(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        return asyncio.run(self._arun(query, max_results))
    
    async def _arun(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """ì¿ íŒ¡ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            # ì¿ íŒ¡ ê²€ìƒ‰ URL êµ¬ì„±
            encoded_query = quote(query)
            search_url = f"https://www.coupang.com/np/search?q={encoded_query}"
            
            # HTTP ìš”ì²­ í—¤ë” ì„¤ì •
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(search_url, headers=headers) as response:
                    if response.status == 200:
                        html = await response.text()
                        return self._parse_coupang_results(html, max_results)
                    else:
                        return {"error": f"HTTP {response.status}", "results": []}
                        
        except Exception as e:
            return {"error": str(e), "results": []}
    
    def _parse_coupang_results(self, html: str, max_results: int) -> Dict[str, Any]:
        """ì¿ íŒ¡ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±"""
        soup = BeautifulSoup(html, 'html.parser')
        products = []
        
        # ì¿ íŒ¡ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì„ íƒì (ì‹¤ì œ ì„ íƒìë¡œ ì—…ë°ì´íŠ¸ í•„ìš”)
        product_items = soup.select('.search-product')[:max_results]
        
        for item in product_items:
            try:
                # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (ì‹¤ì œ ì„ íƒìë¡œ ì—…ë°ì´íŠ¸ í•„ìš”)
                name = item.select_one('.name')
                price = item.select_one('.price-value')
                link = item.select_one('a')
                image = item.select_one('img')
                
                if name and price:
                    product = {
                        "name": name.get_text(strip=True),
                        "price": self._extract_price(price.get_text(strip=True)),
                        "url": urljoin("https://www.coupang.com", link.get('href')) if link else "",
                        "image_url": image.get('src') if image else "",
                        "shop": "ì¿ íŒ¡",
                        "shipping_fee": 0  # ì¿ íŒ¡ì€ ëŒ€ë¶€ë¶„ ë¬´ë£Œë°°ì†¡
                    }
                    products.append(product)
                    
            except Exception as e:
                continue
        
        return {
            "shop": "ì¿ íŒ¡",
            "query": html[:100] + "...",  # ë””ë²„ê¹…ìš©
            "total_results": len(products),
            "results": products
        }
    
    def _extract_price(self, price_text: str) -> int:
        """ê°€ê²© í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        price_numbers = re.findall(r'[\d,]+', price_text.replace(',', ''))
        return int(price_numbers[0]) if price_numbers else 0

class EleventhStreetCrawler(BaseTool):
    """11ë²ˆê°€ í¬ë¡¤ëŸ¬"""
    name = "11st_search"
    description = "11ë²ˆê°€ì—ì„œ ìƒí’ˆì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    args_schema = ShoppingCrawlerInput
    
    def _run(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        return asyncio.run(self._arun(query, max_results))
    
    async def _arun(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """11ë²ˆê°€ ê²€ìƒ‰ ì‹¤í–‰"""
        # 11ë²ˆê°€ í¬ë¡¤ë§ ë¡œì§ êµ¬í˜„
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë°˜í™˜
        await asyncio.sleep(1)
        
        mock_products = []
        for i in range(max_results):
            mock_products.append({
                "name": f"{query} - 11ë²ˆê°€ ìƒí’ˆ {i+1}",
                "price": 155000 + (i * 5000),
                "url": f"https://11st.co.kr/product{i+1}",
                "image_url": f"https://11st.co.kr/image{i+1}.jpg",
                "shop": "11ë²ˆê°€",
                "shipping_fee": 2500
            })
        
        return {
            "shop": "11ë²ˆê°€",
            "query": query,
            "total_results": len(mock_products),
            "results": mock_products
        }

class MultiShoppingCrawler(BaseTool):
    """ë‹¤ì¤‘ ì‡¼í•‘ëª° í¬ë¡¤ëŸ¬"""
    name = "multi_shop_search"
    description = "ì—¬ëŸ¬ ì‡¼í•‘ëª°ì—ì„œ ë™ì‹œì— ìƒí’ˆì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    args_schema = ShoppingCrawlerInput
    
    def __init__(self):
        super().__init__()
        self.crawlers = [
            CoupangCrawler(),
            EleventhStreetCrawler()
            # ì¶”ê°€ í¬ë¡¤ëŸ¬ë“¤...
        ]
    
    def _run(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        return asyncio.run(self._arun(query, max_results))
    
    async def _arun(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ì‡¼í•‘ëª° ë™ì‹œ ê²€ìƒ‰"""
        try:
            # ëª¨ë“  í¬ë¡¤ëŸ¬ë¥¼ ë™ì‹œì— ì‹¤í–‰
            tasks = []
            for crawler in self.crawlers:
                task = crawler._arun(query, max_results // len(self.crawlers))
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ í†µí•©
            all_products = []
            shop_results = {}
            
            for i, result in enumerate(results):
                if isinstance(result, dict) and "results" in result:
                    shop_name = result.get("shop", f"Shop_{i}")
                    shop_results[shop_name] = result
                    all_products.extend(result["results"])
            
            # ê°€ê²©ìˆœ ì •ë ¬
            all_products.sort(key=lambda x: x.get("price", float('inf')))
            
            return {
                "query": query,
                "total_shops": len(self.crawlers),
                "total_products": len(all_products),
                "products": all_products[:max_results],
                "shop_results": shop_results
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "query": query,
                "products": []
            }

def get_shopping_crawlers() -> List[BaseTool]:
    """ì‡¼í•‘ëª° í¬ë¡¤ëŸ¬ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    return [
        MultiShoppingCrawler(),
        CoupangCrawler(),
        EleventhStreetCrawler()
    ]
```

### 4.5 í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±

#### MCP ì—°ë™ í…ŒìŠ¤íŠ¸ (`tests/test_agent/test_mcp_integration.py`)
```python
import pytest
import asyncio
from src.agent.mcp.adapter import MCPToolAdapter
from src.agent.tools.web_search_tools import get_mcp_tools
from src.agent.tools.shopping_crawlers import get_shopping_crawlers

@pytest.fixture
def mcp_adapter():
    """MCP ì–´ëŒ‘í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return MCPToolAdapter()

@pytest.mark.asyncio
async def test_mcp_adapter_initialization(mcp_adapter):
    """MCP ì–´ëŒ‘í„° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    assert mcp_adapter is not None
    assert isinstance(mcp_adapter.tools, list)

@pytest.mark.asyncio
async def test_web_search_tool():
    """ì›¹ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸"""
    tools = get_mcp_tools()
    web_search_tool = next((tool for tool in tools if tool.name == "web_search"), None)
    
    assert web_search_tool is not None
    
    result = await web_search_tool._arun("ì•„ì´í° 15", max_results=3)
    assert "results" in result
    assert isinstance(result["results"], list)

@pytest.mark.asyncio
async def test_shopping_crawlers():
    """ì‡¼í•‘ëª° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸"""
    crawlers = get_shopping_crawlers()
    multi_crawler = next((tool for tool in crawlers if tool.name == "multi_shop_search"), None)
    
    assert multi_crawler is not None
    
    result = await multi_crawler._arun("ê°¤ëŸ­ì‹œ S24", max_results=5)
    assert "products" in result
    assert isinstance(result["products"], list)

@pytest.mark.asyncio
async def test_agent_with_mcp():
    """MCP ì—°ë™ëœ Agent í…ŒìŠ¤íŠ¸"""
    from src.agent.core import PriceFinderAgent
    
    agent = PriceFinderAgent()
    result = await agent.process_message("ì•„ì´í° 15 ìµœì €ê°€ ì°¾ì•„ì¤˜", "test-session")
    
    assert "success" in result
    assert "tools_used" in result
    
    # ì •ë¦¬
    await agent.close()
```

## âœ… ì™„ë£Œ ê¸°ì¤€
- [ ] langchain-mcp-adapters ì„¤ì¹˜ ë° ì„¤ì •
- [ ] MCP ì–´ëŒ‘í„° í´ë˜ìŠ¤ êµ¬í˜„
- [ ] ì›¹ ê²€ìƒ‰ ë° ë¸Œë¼ìš°ì € ë„êµ¬ êµ¬í˜„
- [ ] ì‹¤ì œ ì‡¼í•‘ëª° í¬ë¡¤ë§ ë„êµ¬ êµ¬í˜„ (ì¿ íŒ¡, 11ë²ˆê°€ ë“±)
- [ ] Agentì™€ MCP ë„êµ¬ ì—°ë™ ì™„ë£Œ
- [ ] ë‹¤ì¤‘ ì‡¼í•‘ëª° ë™ì‹œ ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
- [ ] MCP ì—°ë™ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±
- [ ] ì‹¤ì œ ìƒí’ˆ ê²€ìƒ‰ ë™ì‘ í™•ì¸
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° í´ë°± ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. MCP ë„êµ¬ ë‹¨ë… í…ŒìŠ¤íŠ¸
```bash
pytest tests/test_agent/test_mcp_integration.py -v
```

### 2. ì‹¤ì œ ì‡¼í•‘ëª° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
```bash
# ì„œë²„ ì‹¤í–‰
python scripts/run_api.py

# ì‹¤ì œ ìƒí’ˆ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "ì•„ì´í° 15 Pro 256GB ìµœì €ê°€ ì°¾ì•„ì¤˜", "session_id": "test-session"}'
```

### 3. ë‹¤ì¤‘ ì‡¼í•‘ëª° ê²€ìƒ‰ í™•ì¸
```bash
# ì—¬ëŸ¬ ì‡¼í•‘ëª° ë™ì‹œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "ì‚¼ì„± ê°¤ëŸ­ì‹œ S24 Ultra ê°€ê²© ë¹„êµí•´ì¤˜", "session_id": "test-session"}'
```

## ğŸ”— ë‹¤ìŒ ë‹¨ê³„
[Phase 2 Step 5 - Streamlit ì±—ë´‡ UI êµ¬í˜„](mdc:.cursor/rules/tasks/phase2-step5-streamlit-ui.mdc)

## ğŸ“š ì°¸ê³  ë¬¸ì„œ
- [ê°œë°œ íƒœìŠ¤í¬ ê³„íš](mdc:.cursor/rules/development-task-plan.mdc)
- [ê¸°ìˆ  ì•„í‚¤í…ì²˜](mdc:.cursor/rules/technical-architecture.mdc)
- [API ëª…ì„¸ì„œ](mdc:.cursor/rules/api-specification.mdc)

